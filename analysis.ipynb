{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f05e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch import nn\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "87797fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"models/checkpoint-71-1.44896/\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(checkpoint)\n",
    "model = GPT2LMHeadModel.from_pretrained(checkpoint)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ce30266",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid = []\n",
    "with open(\"data/process.valid.json\") as fin:\n",
    "    for line in fin.readlines():\n",
    "        valid.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e289fcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    res = tokenizer(data, max_length=256, truncation=True, padding='max_length', return_tensors='pt')\n",
    "    res['labels'] = deepcopy(res['input_ids'])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9db55c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [tokenize(x['text']) for x in valid]\n",
    "valid_dataloader = DataLoader(data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d74a5864",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef8266ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.466373085975647\n",
      "1 1.3611961603164673\n",
      "2 1.5006167888641357\n",
      "3 1.3286750316619873\n",
      "4 1.2899988889694214\n",
      "5 1.3993217945098877\n",
      "6 1.34325110912323\n",
      "7 1.6091742515563965\n",
      "8 1.5511444807052612\n",
      "9 1.4701207876205444\n",
      "10 1.4888849258422852\n",
      "11 1.5127161741256714\n",
      "12 1.4671717882156372\n",
      "13 1.5454691648483276\n",
      "14 1.3994916677474976\n",
      "15 1.5268012285232544\n",
      "16 1.1971253156661987\n",
      "17 1.2060883045196533\n",
      "18 1.4378563165664673\n",
      "19 1.2301539182662964\n",
      "20 1.4487124681472778\n",
      "21 1.3899378776550293\n",
      "22 1.510952115058899\n",
      "23 1.3130519390106201\n",
      "24 1.7263386249542236\n",
      "25 1.5806022882461548\n",
      "26 1.3740794658660889\n",
      "27 1.4311962127685547\n",
      "28 1.7050901651382446\n",
      "29 1.5969243049621582\n",
      "30 1.2378023862838745\n",
      "31 1.7410755157470703\n",
      "32 1.3752601146697998\n",
      "33 1.5047982931137085\n",
      "34 1.5293471813201904\n",
      "35 1.5695821046829224\n",
      "36 1.6975607872009277\n",
      "37 1.360790729522705\n",
      "38 1.4324647188186646\n",
      "39 1.5470514297485352\n",
      "40 1.3905867338180542\n",
      "41 1.2842612266540527\n"
     ]
    }
   ],
   "source": [
    "for step, batch in enumerate(valid_dataloader):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**batch)\n",
    "    loss = outputs.loss\n",
    "    print(step, loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cec1de7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '13000',\n",
       " 'text': '<sos_u> boa noite, pode me dizer quanto de saldo eu tenho? <eos_u><sos_b> [consulta_saldo][req_saldo][cumprimento] <eos_b><sos_a> [req_cpf] <eos_a><sos_r> Sim, Claro. Qual é o seu cpf? <eos_r><sos_u> 978403690-03 <eos_u><sos_b> [consulta_saldo][info_cpf] cpf 978403690-03 <eos_b><sos_a> [req_placa] <eos_a><sos_r> Me informe sua placa, por favor? <eos_r><sos_u> nxi 4451 <eos_u><sos_b> [consulta_saldo][info_placa] cpf 978403690-03 placa nxi 4451 <eos_b><sos_a> [info_valor][req_mais] <eos_a><sos_r> o saldo é de [valor], mais alguma coisa? <eos_r><sos_u> por enquanto nao. obrigado pelas confirmações <eos_u><sos_b> [negacao] cpf 978403690-03 placa nxi 4451 <eos_b><sos_a> [despedida] <eos_a><sos_r> até mais! <eos_r>'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid[16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "057388ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "string = \"<sos_u><sos_u> boa noite, pode me dizer quanto de saldo eu tenho? <eos_u><sos_b> [consulta_saldo][req_saldo][cumprimento] <eos_b><sos_a> [req_cpf] <eos_a><sos_r> Sim, Claro. Qual é o seu cpf? <eos_r><sos_u> 978403690-03 <eos_u><sos_b> [consulta_saldo][info_cpf] cpf 978403690-03 <eos_b><sos_a> [req_placa] <eos_a><sos_r> Me informe sua placa, por favor? <eos_r><sos_u> nxi 4451 <eos_u><sos_b> [consulta_saldo][info_placa] cpf 978403690-03 placa nxi 4451 <eos_b><sos_a> [info_valor][req_mais] <eos_a><sos_r> o saldo é de [valor], mais alguma coisa? <eos_r><sos_u> e para a placa jgm1234<eos_u><sos_b>\"\n",
    "input_ids = tokenizer.encode(string)\n",
    "eos_token = tokenizer.encode(['<eos_r>'])[0]\n",
    "out = model.generate(input_ids=torch.tensor(input_ids).reshape(1,-1),\n",
    "                                 pad_token_id=tokenizer.eos_token_id,\n",
    "                                 max_length=len(input_ids)+60,\n",
    "                                 eos_token_id=eos_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6f39e2e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<sos_u> <sos_u> boa noite, pode me dizer quanto de saldo eu tenho? <eos_u> <sos_b> [consulta_saldo] [req_saldo] [cumprimento] <eos_b> <sos_a> [req_cpf] <eos_a> <sos_r> Sim, Claro. Qual é o seu cpf? <eos_r> <sos_u> 978403690-03 <eos_u> <sos_b> [consulta_saldo] [info_cpf] cpf 978403690-03 <eos_b> <sos_a> [req_placa] <eos_a> <sos_r> Me informe sua placa, por favor? <eos_r> <sos_u> nxi 4451 <eos_u> <sos_b> [consulta_saldo] [info_placa] cpf 978403690-03 placa nxi 4451 <eos_b> <sos_a> [info_valor] [req_mais] <eos_a> <sos_r> o saldo é de [valor], mais alguma coisa? <eos_r> <sos_u> e para a placa jgm1234 <eos_u> <sos_b> [negacao] cpf 978403690-03 placa jgm1234 <eos_b> <sos_a> [despedida] <eos_a> <sos_r> Obrigado pelo contato! Desejo uma boa tarde para você! Tchau! <eos_r>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d303faf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
